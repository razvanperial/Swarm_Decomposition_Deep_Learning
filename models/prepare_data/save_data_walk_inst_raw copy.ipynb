{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal.windows import hann\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../../functions/get_data.ipynb\"\n",
    "%run \"../../functions/bandpass.ipynb\"\n",
    "%run \"../../functions/trimmer.ipynb\"\n",
    "%run \"../../functions/swd.ipynb\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../../data/initial_data/walk_inst_raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = get_file_list(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_data(file_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kick out the discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "discontinuous_files = [('../../capped_data/data/walk_instruction_raw/S_1.mat', [(4, 0, 375), (5, 0, 397), (11, 0, 486), (14, 0, 591), (15, 5, 674), (34, 0, 122), (37, 0, 51), (45, 0, 657)]), ('../../capped_data/data/walk_instruction_raw/S_2.mat', [(16, 0, 618)]), ('../../capped_data/data/walk_instruction_raw/S_3.mat', [(21, 0, 387), (49, 0, 681), (73, 0, 219), (75, 0, 24)]), ('../../capped_data/data/walk_instruction_raw/S_4.mat', [(62, 0, 240)]), ('../../capped_data/data/walk_instruction_raw/S_9.mat', [(34, 0, 37)])]\n",
    "total_found = 15\n",
    "\n",
    "X, Y = trim_discontinuous_files(file_list, discontinuous_files, total_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_out = [(1, [19, 30]), (2, [3, 5, 32, 46]), (3, [14, 39]), (4, [13, 22, 37, 45]), (5, [17]), (7, [13, 31, 37, 49]),\n",
    "            (8, [54]), (9, [0, 8, 12, 15, 39, 40, 44, 45, 50, 55, 57]), (10, [2, 16, 20, 23, 46, 47, 56, 60]), (11, [37, 51, 67, 73, 74]), \n",
    "            (12, [2, 27, 54]), (13, [26, 34, 38, 41, 52, 59, 68])]\n",
    "\n",
    "file_dict = {0: 'P_1', 1: 'P_10', 2: 'P_2', 3: 'P_3', 4: 'P_4', 5: 'P_5', 6: 'P_9', 7: 'S_1', 8: 'S_10', \n",
    "             9: 'S_2', 10: 'S_3', 11: 'S_4', 12: 'S_5', 13: 'S_9'}\n",
    "new_X, new_Y = trim_manually(kick_out, X, Y, file_dict, print_out=False) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut down channels 6, 10 and 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 14, 750) -> (56, 11, 500) (56, 2)\n",
      "(37, 14, 750) -> (35, 11, 500) (35, 2)\n",
      "(49, 14, 750) -> (45, 11, 500) (45, 2)\n",
      "(56, 14, 750) -> (54, 11, 500) (54, 2)\n",
      "(58, 14, 750) -> (54, 11, 500) (54, 2)\n",
      "(57, 14, 750) -> (56, 11, 500) (56, 2)\n",
      "(60, 14, 750) -> (60, 11, 500) (60, 2)\n",
      "(60, 14, 750) -> (56, 11, 500) (56, 2)\n",
      "(67, 14, 750) -> (66, 11, 500) (66, 2)\n",
      "(60, 14, 750) -> (49, 11, 500) (49, 2)\n",
      "(80, 14, 750) -> (72, 11, 500) (72, 2)\n",
      "(79, 14, 750) -> (74, 11, 500) (74, 2)\n",
      "(66, 14, 750) -> (63, 11, 500) (63, 2)\n",
      "(84, 14, 750) -> (77, 11, 500) (77, 2)\n",
      "Total samples removed:  52\n",
      "Total samples remaining:  817\n"
     ]
    }
   ],
   "source": [
    "desired_channels = [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12]\n",
    "for i in range(len(new_X)):\n",
    "    new_X[i] = new_X[i][:, desired_channels, :]\n",
    "\n",
    "print_eliminations(file_list, new_X, new_Y, print_shape=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save one sample of the data to a .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 11, 500)\n",
      "(35, 11, 500)\n",
      "(45, 11, 500)\n",
      "(54, 11, 500)\n",
      "(54, 11, 500)\n",
      "(56, 11, 500)\n",
      "(60, 11, 500)\n",
      "(56, 11, 500)\n",
      "(66, 11, 500)\n",
      "(49, 11, 500)\n",
      "(72, 11, 500)\n",
      "(74, 11, 500)\n",
      "(63, 11, 500)\n",
      "(77, 11, 500)\n"
     ]
    }
   ],
   "source": [
    "for x, i in zip(new_X, range(len(new_X))):\n",
    "    print(x.shape)\n",
    "    scipy.io.savemat(f'../../data/initial_filtered_data/walk_inst_raw/P_{i+1}.mat', {'data': x})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_net_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
